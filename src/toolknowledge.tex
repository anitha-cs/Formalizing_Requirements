\subsection{Challenge 3: Cursory Knowledge of Tools}

Although we used sophisticated tools with advanced capabilities such as consistency checks, cursory knowledge about how the tools perform such checks lead us to successfully verify inconsistent requirements. The tool we used -- AGREE -- had capability to check consistency of requirements in addition to verifying them that detects logical contradictions among requirements. The intent of performing such checks is to identify if the verification was trivially successful due to presence of inconsistent requirements. While the tool declared that all the GPCA requirements are consistent, our tool expert during the manually inspection phase found that there were several self-inconsistent requirements. To our surprise, those inconsistencies were not reported by the tool. This was primarily because we did not have full knowledge of the tool settings associated with that check.

Lets us illustrate the problem with an concrete example. To formalize certain requirements for GPCA we had to specify counters to keep track of duration of internal conditions or occurrence of certain actions. For example, consider a requirement to notify the clinician when the patient requests more than a certain number of boluses. To formalize this requirement we had to count the number of requests received \texttt{(PatientRequest)} by the system. Hence, we declared an integer variable \texttt{(boluscnt)}, whose initial value was 0 and then gets incremented whenever a \texttt{PatientRequest} is received by the system, as shown below. 

$$ \texttt{boluscnt:int = 0 -> boluscnt + PatientRequest} $$

The formal language used to capture the requirements in AGREE is based on Property Specification Language (PSL)~\cite{IEEE-PSL} and defines a Lustre language
~\cite{Caspi87:lustre} ``flavor" for the PSL expressions. Lustre is a synchronous dataflow language that describes the behavior of a system through a set of equations, and it can be viewed as a textual analogue to Simulink block diagrams. In this notation, it is possible to define constants, local variables and reusable fragments of temporal logic (called properties). Additionally, we can describe stateful relationships between variables using
the `pre' expression, which provides the value of a variable from the previous step of execution of the system. In this formalization, ``$->$" is used to capture the sequence of value computations for a variable. For example ``$0 -> 5$" means the value is 0 in the initial execution (or time) step and the value is 5 in all subsequent execution steps.

While the tool successfully verified the requirement involving the \texttt{boluscnt} variable, during manual inspection our tool expert pointed out this statement was internally inconsistent. The inconsistency was due to the usage of \texttt{boluscnt} in both the right and left side of the equation. According to the tool, the value for \texttt{boluscnt} always refers to its value in the current time step, whereas we actually intended to refer to the value in the previous time step in the right side of the expression. The incorrect formulation had caused a circular dependency in assigning values for \texttt{boluscnt} variable, that made this expression and the requirement involving this variable inconsistent and trivially satisfied. In the GPCA, we identified 20 such inconsistent formalizations in both system and component levels. To fix this issue, we used AGREE's operator \emph{``pre"}, to refer to the value of a variable in the previous step as shown below.

$$ \texttt{boluscnt:int = 0 -> pre(boluscnt) + PatientRequest} $$

While adding \emph{``pre"} fixed this specific type of inconsistency, our concern was that the tool's consistency checker did not identify this problem. After discussing with the tool developers, we found that the tool was set up by default to check for consistency only in the initial time step (first step of execution). This was not a bug in the tool, rather an intensional default setting to optimize the performance of the tool. According to the tool developers, most inconsistencies can be found in the first step and this was an exceptional condition. Since the \texttt{boluscnt} equation was inconsistent only after the initial step (its initial value was 0), the consistency checker did not report the problem.

In our opinion, this situation is not limited to this specific example or tool but generalizable for all model checking tools and techniques. The root cause of this problem is not just our cursory knowledge of the tools, but also the lack of adequate details of the task displayed by the tool.


\subsubsection {Solution: Understanding Tool Settings}

We believe that the root cause of the AGREE tool not being able to identify the consistency issues in the formalized requirements was because the tool had an incorrect default setting, but the fact that we were not aware of that setting and it was not apparent in the results. Hence, to address the issue from the tool side we requested the tool developers to provide elaborate messages of certain key configurations when using the features, that play a key role in determining their correctness. After that change, AGREE now displays the depth of consistency check along with the results. While such a change may not be possible with every tool and feature we use, we strongly recommend the engineers to delve deep into the details and configuration of tool to precisely understand the results, especially when there is limited information provided by the tool along with the results. %Additionally, this error motivated the tool developers to enhance the AGREE tool to check for \emph{vacuity}. We believe with vacuity checking we could effectively identify some of these issues.


%To mitigate this problem, in addition to validating the formalization with domain and tool experts, an indepth understanding of the tool settings that performs such checks and validations, rather than blindly trusting the results from the tool.


%Hence, when the tool developers
%
%Although the tool was sophisticated enough to allow this default setting to be changed, the real problem was our cursory knowledge about the tool and the fact that it was not obvious from the tool results. While we fixed this issue by both changing the formalization as well as enhancing the tool to display the number of time steps for consistency check, the risk of specifying such inconsistent requirements could only be avoided if we had through understanding of the tool.
%
%
